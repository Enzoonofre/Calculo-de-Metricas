# -*- coding: utf-8 -*-
"""Matriz de confusão.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kLgwdUnXn_U9_rF8uH3BtFhvvl9mGUta
"""

import pandas as pd

df = pd.read_csv('train.csv')
df_test = pd.read_csv('test.csv')
test_text = df_test['text']
text = df['text']
target = df['target']

print(target)

from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(text)
y = target
X_test_final = vectorizer.transform(test_text)

from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split



X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.1, random_state = 1)
mlp = MLPClassifier(hidden_layer_sizes=(50), activation= 'logistic',random_state = 1,solver='adam', alpha=0.0001, learning_rate='adaptive', max_iter=500).fit(X_train, y_train)

from sklearn.metrics import confusion_matrix
y_pred = mlp.predict(X_test)

conf_matrix = confusion_matrix(y_test, y_pred)
print("Matriz de Confusão:")
print(conf_matrix)

"""##Instanciando os componentes para calcular as métricas"""

VP = conf_matrix[0, 0]  # Verdadeiros negativos
FN = conf_matrix[0, 1]  # Falsos positivos
FP = conf_matrix[1, 0]  # Falsos negativos
VN = conf_matrix[1, 1]  # Verdadeiros positivos

acuracia = (VP+VN)/(conf_matrix.sum())
print("Acurácia:", acuracia)
recall = VP/(VP+FN)
print("Recall:", recall)
especificidade = VN/(VN+FP)
print("Especificidade:", especificidade)
precisão = VP/(VP+FP)
print("Precisão:", precisão)
f1_score = (2*precisão*recall)/(precisão+recall)
print("F1 Score:", f1_score)

import matplotlib.pyplot as plt

# Definição das métricas
metricas = ["Acurácia", "Recall", "Especificidade", "Precisão", "F1 Score"]
valores = [acuracia, recall, especificidade, precisão, f1_score]

# Criando o gráfico de barras
plt.figure(figsize=(8, 5))
plt.bar(metricas, valores, color=['blue', 'green', 'orange', 'red', 'purple'])

# Adicionando valores acima das barras
for i, v in enumerate(valores):
    plt.text(i, v + 0.02, f"{v:.2f}", ha='center', fontsize=12)


plt.ylim(0, 1)
plt.xlabel("Métricas")
plt.ylabel("Valor")
plt.title("Métricas do Modelo")
plt.show()

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
y_probs = mlp.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_probs)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(8,6))
plt.plot(fpr, tpr, label=f'Curva ROC (AUC = {roc_auc:.4f})', color='blue')
plt.plot([0, 1], [0, 1], 'r--')
plt.xlabel('Taxa de Falsos Positivos (FPR)')
plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')
plt.title('Curva ROC')
plt.legend()
plt.show()